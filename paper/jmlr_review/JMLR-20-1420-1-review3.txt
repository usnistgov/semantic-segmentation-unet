Summary of Review:
This paper covers not a new method, nor a new analysis, but an instructive warning and solution on how to properly divide computation for fully convolutional networks in order to respect practical limits of memory on specialized hardware like GPUs. I appreciate the purpose of this paper, in warning about the wrong computation, diagnosing its errors, and seeking to remedy it by explaining the right computation. It is surely regrettable that researchers, engineers, and users of all sorts are confused by how to tile correctly, and more progress would be made if their mistakes were fixed. While I am certain the right way is known to experts, there is clearly a target audience in the community that would be informed by this work.

However, the goal of reaching this audience and instructing them requires the explanation to be abundantly clear and the justification thoroughly grounded in popular methods and data. For adoption, and therefore impact, this work needs revision to (1) improve clarity and comprehensiveness, (2) evaluate on current models and benchmarks, and (3) ideally point out more cases where wrong tiling has held back progress.

Summary of Paper:
Fully convolutional networks are models that filter an input image into an output image, and as filters they can process inputs of varying spatial size. However, practical limits can constrain the the size of the input, in particular the amount of memory on specialized hardware like GPUs. With care, this limit can be entirely sidestepped by exchanging memory for time: dividing the input into tiles of the correct side and stride only requires finite memory no matter how many tiles are produced in this way. The correct tiling depends on the network, specifically the fundamental quantities of receptive field size (the amount of the input processed in the inference of each output) and stride (the spatial offset between each output). The sources of error for incorrect tilings are identified, in Section 3.2, and case study for how to compute the correct quantities for the U-Net architecture is walked through, in Section 3.1. There are toy illustrations of how the wrong choice of tiling impacts results (Figure 3).

Experiments verify the error for incorrect tiles and lack of error for correct tiles on a microscopy segmentation task with two different architectures. These experiments measure not only errors in the output values (root mean square error), but also the errors in the task (misclassification error), and normalize these measures by the number of pixels. Further experiment refines the calculation of the tiling quantities to account for not only network architecture but network parameters, in estimating the *effective* receptive field of a model, which can be smaller than its architectural receptive field.

Pro:
- There is a real usage mistake here, which is made in practice. I have had to explain correct tiling, as addressed by this work, in both teaching and consulting. While some now how to do it right, there are members of the community that could use instruction on this subject.
- There is also a real computational issue: mistakes in tiling are made because there is a need for tiling, especially in medical imaging and remote sensing, where inputs are large.
- The tiling rules given here are general, within the scope of the explanation (convolution and pooling layers), and so apply to not only vision but other modalities.
- There are both illustrative and real examples of tiling errors and their causes, like the segmentation errors that result without the necessary input halo for correct tiling.
- The paper is clear about the plusses and minusses of correct tiling: it prevents errors in inference, but requires more computation (because of the necessary input halo/boundary for each output tile).
- Measuring the effective receptive field, counter to the architectural receptive field, makes it possible to use smaller tiles than the architecture indicates.
- There is some discussion of limitations, such as the potential issues with tiling of models that include normalization, dynamic receptive fields, or non-local steps like pairwise attention.
- Code is included for the specific case of the model and dataset considered. This has some explanatory value, but code to calculate the correct tiling quantities would be both more explanatory and more practically useful.

Con:
- The explanation of correct tiling is too literal, and low-level. It stays close to the details of the chosen model, U-Net, and does not clearly explain the rules in generality. For instance, it concretely talks of max pooling, rather than other possibly strided operations (like convolution, or other varieties of pooling). Likewise dilation, a common argument to convolution, is not discussed in determining the receptive field. For a tutorial on this subject, I would expect general equations that can be worked through to derive the receptive field size, stride, and offset (shift w.r.t. the input) of any feature or output. With these explained, an explanation of the zone of responsibility and halo for tiling would directly.
- The paper is not so self-contained, as it refers to details of computation (shift-and-stitch inference) and model architecture (U-Net and DenseNet) without unpacking them. Since the subject of the paper, like its case study of tiling for U-Net, depends on these details they are worth explaining in the paper without requiring external reference.
- The treatment of normalization and non-local operations is insufficient. These are not uncommon parts of models now, and so it worthwhile to measure the effect of tiling on them, as the effect could empirically be large or small. There is a passing mention of batch normalization, but during inference batch normalization is fixed and has no dependence on the input. The issue with tiling would only arise during training, or with other popular normalization like group norm. Experiments for these cases would round out the paper nicely, to more comprehensively cover networks as they now are.
- The choice of dataset, stem cell microscopy images, is an uncommon one, and the networks studied are older than current. While the tiling principles explained here are independent of any given architecture, and so the evidence provided is valid, it would be more compelling to show this for a popular benchmark. For instance, one could choose a recent MICCAI challenge in medical imaging, or look at the Cityscapes dataset for segmentation, which can already pose issues for large enough networks.

Feedback for Authors (for improvement, not for rating or decision):
- The terminology of "error-free" and "out-of-core" may be problematic for some readers. Inference is not "error-free" with respect to the task, the model is as good as it is, but "artifact-free" in that correct tiling does not introduce errors into inference. "Out-of-core" may be unfamiliar to those with less systems experience, while "in bounded memory" or "in constant memory" or "without memory constraints" might be more accessible. Taking a step back, I advise rewriting the abstract and introduction in plainer terms and then defining specific terminology.
- Consider moving Figure 1 or 2 into the introduction, for a more immediate visual explanation. The figures should label the zone of responsibility and halo in the visuals to be more instantly parsed by the reader.
- Section 3: Why have "level" at all? Isn't stride/sampling rate the more fundamental quality? This section might be more clear by first covering the notation of primitive quantities, like kernel size, stride, dilation, padding, etc. and then composing them into rules for receptive field size, stride w.r.t. the input, and offset. Currently, the explanation does not consider offset at all, but it is possible for architectures to be spatially misaligned by operations that result in spatial shifts of coordinates (like downsampling with even kernel sizes, rather than odd sizes).
- Replace use of "inference" as a verb with "infer" for grammaticality.
- Prefer "parameters" rather than "coefficients" when talking about models, as that is the common usage in deep learning.
- Typos: "Mihn" for "Minh", "we us" for "we use", "whole image being is", "tiliing" error